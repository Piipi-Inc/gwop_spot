{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.embeddings.sentence_transformer import (\n",
    "    SentenceTransformerEmbeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "# Load environment variables\n",
    "load_dotenv('../../.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0, max_tokens = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_articles = pd.read_csv('../../data/df_articles.csv').dropna()\n",
    "df_articles['content'] = df_articles['title'] + df_articles['content']\n",
    "\n",
    "df_articles_analytics = pd.read_csv('../../data/df_articles_analytics.csv').dropna()\n",
    "df_articles_analytics['content'] = df_articles_analytics['title'] + df_articles_analytics['content']\n",
    "\n",
    "documents = df_articles['content'].to_list() + df_articles_analytics['content'].to_list()\n",
    "with open('../../data/courses.txt', 'r') as f:\n",
    "    documents += list(f.read().split('\\n\\n\\n\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [doc.replace('\\xa0', ' ').replace('\\n', ' ') for doc in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "525"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = text_splitter.split_text(\" \".join(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name DeepPavlov/rubert-base-cased-sentence. Creating a new one with mean pooling.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "# create the open-source embedding function\n",
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"DeepPavlov/rubert-base-cased-sentence\", model_kwargs={'device': 'cpu'})\n",
    "\n",
    "db = Chroma.from_texts(chunks, embedding_function, persist_directory=\"../../artifacts/chroma_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# –°–æ—Ö—Ä–∞–Ω—è–µ–º chain –∫–∞–∫ pickle\n",
    "with open(\"../../artifacts/embedding_function.pkl\", \"wb\") as file:\n",
    "    pickle.dump(embedding_function, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# Multi Query: Different Perspectives\n",
    "template = \"\"\"You are an AI language model assistant. Your task is to generate five \n",
    "different versions of the given user question to retrieve relevant documents from a vector \n",
    "database. By generating multiple perspectives on the user question, your goal is to help\n",
    "the user overcome some of the limitations of the distance-based similarity search. \n",
    "Provide these alternative questions separated by newlines. Original question: {question}\"\"\"\n",
    "prompt_perspectives = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "generate_queries = (\n",
    "    prompt_perspectives \n",
    "    | llm\n",
    "    | StrOutputParser() \n",
    "    | (lambda x: x.split(\"\\n\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.load import dumps, loads, load\n",
    "\n",
    "def get_unique_union(documents: list[list]):\n",
    "    \"\"\" Unique union of retrieved docs \"\"\"\n",
    "    # Flatten list of lists, and convert each Document to string\n",
    "    flattened_docs = [dumps(doc) for sublist in documents for doc in sublist]\n",
    "    # Get unique documents\n",
    "    unique_docs = list(set(flattened_docs))\n",
    "    # Return\n",
    "    return [loads(doc) for doc in unique_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"–ö–∞–∫–∏–µ –∞–∫—Ü–∏–∏ IT –∫–æ–º–ø–∞–Ω–∏–π —Å–µ–π—á–∞—Å –Ω–∞–∏–±–æ–ª–µ–µ –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã –¥–ª—è –ø—Ä–∏–æ–±—Ä–µ—Ç–µ–Ω–∏—è?\"\n",
    "retrieval_chain = generate_queries | retriever.map() | get_unique_union\n",
    "docs = retrieval_chain.invoke({\"question\":question})\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='–ø–æ–µ—Ö–∞–ª–∏! –í —ç—Ç–æ–º —É—Ä–æ–∫–µ –º—ã –¥–∞–¥–∏–º –≤–∞–º —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π —á–µ–∫-–ª–∏—Å—Ç. –° –Ω–∏–º –≤—ã –≤ –ª—é–±–æ–π –º–æ–º–µ–Ω—Ç –±—ã—Å—Ç—Ä–æ –æ—Ü–µ–Ω–∏—Ç–µ —Å–∏—Ç—É–∞—Ü–∏—é –≤–æ–∫—Ä—É–≥ –∏ –ø–æ–¥–±–µ—Ä–µ—Ç–µ —Å–µ–±–µ –∞–∫—Ç–∏–≤. ‚òùüèª –•–æ—Ä–æ—à–∞—è –Ω–æ–≤–æ—Å—Ç—å: —á–µ–∫-–ª–∏—Å—Ç –ø–æ–¥–æ–π–¥–µ—Ç –Ω–µ —Ç–æ–ª—å–∫–æ –¥–ª—è –≤—ã–±–æ—Ä–∞ –∞–∫—Ü–∏–π, –Ω–æ –∏ –µ—Å–ª–∏ –≤—ã –∑–∞—Ö–æ—Ç–∏—Ç–µ –ø—Ä–∏—Å–º–æ—Ç—Ä–µ—Ç—å—Å—è –∫ –æ–±–ª–∏–≥–∞—Ü–∏—è–º –∏–ª–∏ —Ñ–æ–Ω–¥–∞–º. –í–æ–æ–±—â–µ, –∫–æ–≥–¥–∞ –º—ã –≥–æ–≤–æ—Ä–∏–º –ø—Ä–æ –≤—ã–±–æ—Ä –∞–∫—Ç–∏–≤–æ–≤, –ø—Ä–∏–Ω—Ü–∏–ø –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏ –æ–¥–∏–Ω–∞–∫–æ–≤—ã–π. –ü–æ—ç—Ç–æ–º—É –º—ã –∏ –Ω–∞–∑–≤–∞–ª–∏ —á–µ–∫-–ª–∏—Å—Ç —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–º üßê –ù—É —á—Ç–æ, –ø–æ–µ—Ö–∞–ª–∏! 1. –ù–æ–≤–æ—Å—Ç–∏ –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ –∫–æ–º–ø–∞–Ω–∏–∏ –ø–µ—Ä–µ–¥ –ø–æ–∫—É–ø–∫–æ–π ‚Äî –¥–µ–ª–æ –≤–∞–∂–Ω–æ–µ, –Ω–æ –Ω–µ –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω–æ–µ. –ò–Ω–≤–µ—Å—Ç–æ—Ä –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤ –∫—É—Ä—Å–µ —Å–æ–±—ã—Ç–∏–π, —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Å –∫–æ–º–ø–∞–Ω–∏–µ–π, —á—Ç–æ–±—ã –Ω–µ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å —á—Ç–æ-—Ç–æ –≤–∞–∂–Ω–æ–µ (–∞–≤–∞—Ä–∏–∏, —Ñ–æ—Ä—Å-–º–∞–∂–æ—Ä—ã, —Å–ª–∏—è–Ω–∏–µ, –≤—ã–ø–ª–∞—Ç—É –¥–∏–≤–∏–¥–µ–Ω–¥–æ–≤ –∏ –ø—Ä–æ—á–µ–µ). ü§î –ó–∞—á–µ–º —Å–º–æ—Ç—Ä–µ—Ç—å –°–ª—É—Ö–∏ –∏ –Ω–æ–≤–æ—Å—Ç–∏ –æ –∫–æ–º–ø–∞–Ω–∏–∏, –≤—ã—Å–∫–∞–∑—ã–≤–∞–Ω–∏—è –ø–µ—Ä–≤—ã—Ö –ª–∏—Ü –∏–ª–∏ –∂–µ –¥—Ä—É–≥–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è, –∏–º–µ—é—â–∞—è –ø—Ä—è–º–æ–µ –∏–ª–∏ –∫–æ—Å–≤–µ–Ω–Ω–æ–µ –æ—Ç–Ω–æ—à–µ–Ω–∏–µ –∫ –±–∏–∑–Ω–µ—Å—É –∫–æ–º–ø–∞–Ω–∏–∏, –º–æ–≥—É—Ç –ø–æ–≤–ª–∏—è—Ç—å –Ω–∞ –∫–æ—Ç–∏—Ä–æ–≤–∫–∏. 1. –ù–æ–≤–æ—Å—Ç–∏ –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ –∫–æ–º–ø–∞–Ω–∏–∏ –ø–µ—Ä–µ–¥ –ø–æ–∫—É–ø–∫–æ–π ‚Äî –¥–µ–ª–æ –≤–∞–∂–Ω–æ–µ, –Ω–æ'),\n",
       " Document(page_content='–ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–µ –∑–∞ —Å—á–µ—Ç –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ —Ä–æ—Å—Ç–∞ –ø—Ä–æ–¥–∞–∂ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Ä–µ—à–µ–Ω–∏–π.     –ë–µ–Ω–µ—Ñ–∏—Ü–∏–∞—Ä —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π IT-—Ä—ã–Ω–∫–∞ –ö–∞–∫ –º—ã –æ—Ç–º–µ—á–∞–ª–∏ –≤—ã—à–µ, –∫–æ–º–ø–∞–Ω–∏—è –≤—ã–∏–≥—Ä—ã–≤–∞–µ—Ç –æ—Ç –ø–µ—Ä–µ—Å—Ç—Ä–æ–π–∫–∏ —Ä—ã–Ω–∫–∞, –∫–æ—Ç–æ—Ä–∞—è –Ω–∞—á–∞–ª–∞—Å—å –≤ 2022 –≥–æ–¥—É. –ê–∫—Ç–∏–≤–Ω–æ–µ –∏–º–ø–æ—Ä—Ç–æ–∑–∞–º–µ—â–µ–Ω–∏–µ —Ç–∞–∫–∂–µ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ —Å–∫–∞–∑—ã–≤–∞–µ—Ç—Å—è –Ω–∞ –ø—Ä–∏–±—ã–ª—å–Ω–æ—Å—Ç–∏ –∫–æ–º–ø–∞–Ω–∏–∏, –Ω–æ —É–∂–µ –≤ —Å–µ–≥–º–µ–Ω—Ç–µ —Ä–µ—à–µ–Ω–∏–π —Å—Ç–æ—Ä–æ–Ω–Ω–∏—Ö –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª–µ–π. –í —Ü–µ–ª–æ–º –≤–∞–ª–æ–≤–∞—è –º–∞—Ä–∂–∞ –∫–æ–º–ø–∞–Ω–∏–∏ –∫–∞–∫ % –æ—Ç –ø—Ä–æ–¥–∞–∂ –≤—ã—Ä–æ—Å–ª–∞ —Å 14,9% –≤ 2020-–º –¥–æ 26% –≤ 2023-–º. M&A-—Å–¥–µ–ª–∫–∏ –∫–∞–∫ –¥—Ä–∞–π–≤–µ—Ä —Ä–æ—Å—Ç–∞ –≤ —Å—Ä–µ–¥–Ω–µ—Å—Ä–æ—á–Ω–æ–π –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–µ –°–æ—Ñ—Ç–ª–∞–π–Ω –æ–±–ª–∞–¥–∞–µ—Ç –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–º –æ–ø—ã—Ç–æ–º –≤ —Å–æ–≤–µ—Ä—à–µ–Ω–∏–∏ —Å–¥–µ–ª–æ–∫ —Å–ª–∏—è–Ω–∏–π –∏ –ø–æ–≥–ª–æ—â–µ–Ω–∏–π. –¢–æ–ª—å–∫–æ —Å –Ω–∞—á–∞–ª–∞ —ç—Ç–æ–≥–æ –≥–æ–¥–∞ –∫–æ–º–ø–∞–Ω–∏—è –∑–∞–≤–µ—Ä—à–∏–ª–∞ –±–æ–ª–µ–µ –≤–æ—Å—å–º–∏ –ø–æ–¥–æ–±–Ω—ã—Ö —Å–¥–µ–ª–æ–∫. –ü—Ä–∏—á–µ–º —Å–¥–µ–ª–∞–ª–∞ —ç—Ç–æ –≤ —Ä–∞–∑–Ω—ã—Ö —Å–µ–≥–º–µ–Ω—Ç–∞—Ö —Ä—ã–Ω–∫–∞ –∏ –¥–ª—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ü–µ–ª–µ–π, –≤–∫–ª—é—á–∞—è –ø—Ä–∏–≤–ª–µ—á–µ–Ω–∏–µ IT-—Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–æ–≤, —Ä–∞–∑–≤–∏—Ç–∏–µ –ø–æ—Ä—Ç—Ñ–µ–ª—è —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Ä–µ—à–µ–Ω–∏–π –∏ —ç–∫—Å–ø–∞–Ω—Å–∏—é –≤ –Ω–æ–≤—ã–µ —Å–µ–≥–º–µ–Ω—Ç—ã. –ü—Ä–∏ —ç—Ç–æ–º –Ω–∞ —Ñ–æ–Ω–µ —Ä–æ—Å—Ç–∞ —É—Ä–æ–≤–Ω—è –∫–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏–∏ —Ä—ã–Ω–∫–∞ –∏ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ü–∏–∏ –∑–∞ –æ—Å–≤–æ–±–æ–¥–∏–≤—à–∏–µ—Å—è –Ω–∏—à–∏ –º–Ω–æ–≥–∏–º –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –Ω–µ–±–æ–ª—å—à–∏–º'),\n",
       " Document(page_content='–ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç–µ–ª–∏ B2B- –∏ B2G-—Å–µ–∫—Ç–æ—Ä–æ–≤. –ö–ª–∏–µ–Ω—Ç—Å–∫–∞—è –±–∞–∑–∞ –∫–æ–º–ø–∞–Ω–∏–∏ –¥–æ–≤–æ–ª—å–Ω–æ –¥–∏–≤–µ—Ä—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–∞: –¥–æ–ª—è —Ç–æ–ø-5 –∑–∞–∫–∞–∑—á–∏–∫–æ–≤ –Ω–µ –ø—Ä–µ–≤—ã—à–∞–µ—Ç 10% –æ—Ç –≤—ã—Ä—É—á–∫–∏. –§–∞–∫—Ç–æ—Ä—ã –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–æ–Ω–Ω–æ–π –ø—Ä–∏–≤–ª–µ–∫–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –†–∞–∑–≤–∏—Ç–∏–µ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã—Ö –ø—Ä–æ–¥—É–∫—Ç–æ–≤ –ü–æ –Ω–∞—à–µ–º—É –º–Ω–µ–Ω–∏—é, —Ä–∞–∑–≤–∏—Ç–∏–µ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã—Ö –ø—Ä–æ–¥—É–∫—Ç–æ–≤ —è–≤–ª—è–µ—Ç—Å—è –æ—Å–Ω–æ–≤–Ω—ã–º —Ñ–∞–∫—Ç–æ—Ä–æ–º –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–æ–Ω–Ω–æ–π –ø—Ä–∏–≤–ª–µ–∫–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∫–æ–º–ø–∞–Ω–∏–∏. –î–æ–ª—è —ç—Ç–∏—Ö –ø—Ä–æ–¥—É–∫—Ç–æ–≤ –≤ –æ–±—â–µ–º –æ–±—ä–µ–º–µ –ø—Ä–æ–¥–∞–∂ –∑–∞ –ø–µ—Ä–≤–æ–µ –ø–æ–ª—É–≥–æ–¥–∏–µ 2024-–≥–æ –≤—ã—Ä–æ—Å–ª–∞ –¥–æ 30% —Å –º–µ–Ω–µ–µ 3% –≤ 2020 –≥–æ–¥—É. –≠—Ç–æ –ø–æ–∑–∏—Ç–∏–≤–Ω–æ —Å–∫–∞–∑—ã–≤–∞–µ—Ç—Å—è –Ω–∞ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –±–∏–∑–Ω–µ—Å–∞, –ø–æ—Å–∫–æ–ª—å–∫—É —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è –±–æ–ª–µ–µ —Ä–µ–Ω—Ç–∞–±–µ–ª—å–Ω—ã–µ, —á–µ–º –ø—Ä–æ–¥—É–∫—Ç—ã —Å—Ç–æ—Ä–æ–Ω–Ω–∏—Ö –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª–µ–π. –¢–∞–∫, –≤–∞–ª–æ–≤–∞—è –ø—Ä–∏–±—ã–ª—å –∫–∞–∫ % –æ—Ç –ø—Ä–æ–¥–∞–∂ —É —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã—Ö –ø—Ä–æ–¥—É–∫—Ç–æ–≤ —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç –≤ —Å—Ä–µ–¥–Ω–µ–º –æ–∫–æ–ª–æ 60%, –∞ —É —Å—Ç–æ—Ä–æ–Ω–Ω–∏—Ö –ø—Ä–æ–¥—É–∫—Ç–æ–≤ ‚Äî –≤—Å–µ–≥–æ –æ–∫–æ–ª–æ 13%. –ñ–¥–µ–º —É–≤–µ–ª–∏—á–µ–Ω–∏—è –≤–∞–ª–æ–≤–æ–π –º–∞—Ä–∂–∏ –∫–æ–º–ø–∞–Ω–∏–∏ –≤ —Å—Ä–µ–¥–Ω–µ—Å—Ä–æ—á–Ω–æ–π –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–µ –∑–∞ —Å—á–µ—Ç –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ —Ä–æ—Å—Ç–∞ –ø—Ä–æ–¥–∞–∂ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Ä–µ—à–µ–Ω–∏–π.     –ë–µ–Ω–µ—Ñ–∏—Ü–∏–∞—Ä —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π IT-—Ä—ã–Ω–∫–∞ –ö–∞–∫ –º—ã –æ—Ç–º–µ—á–∞–ª–∏ –≤—ã—à–µ, –∫–æ–º–ø–∞–Ω–∏—è –≤—ã–∏–≥—Ä—ã–≤–∞–µ—Ç –æ—Ç –ø–µ—Ä–µ—Å—Ç—Ä–æ–π–∫–∏ —Ä—ã–Ω–∫–∞, –∫–æ—Ç–æ—Ä–∞—è'),\n",
       " Document(page_content='—Å –∏—Å—Ç–æ—Ä–∏—è–º–∏ ‚Äî –≤–∞–∂–Ω–∞—è –∏ –ø–æ–ª–µ–∑–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è, –∞ —Ç–∞–∫–∂–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –∞–Ω–∞–ª–∏—Ç–∏–∫–æ–≤ –ø–æ–Ω—è—Ç–Ω—ã–º –∏ –±–æ–¥—Ä—ã–º —è–∑—ã–∫–æ–º. üëâ –ù—É –∏ –≤-—á–µ—Ç–≤–µ—Ä—Ç—ã—Ö, –≤–∫–ª–∞–¥–∫–∞ ¬´–ò–∑–±—Ä–∞–Ω–Ω–æ–µ¬ª ‚Äî –±—É–º–∞–≥–∏, –∫–æ—Ç–æ—Ä—ã–µ –≤–∞–º –ø–æ–Ω—Ä–∞–≤–∏–ª–∏—Å—å –∏ –∫–æ—Ç–æ—Ä—ã–µ –≤—ã –æ—Ç–º–µ—Ç–∏–ª–∏ –∑–≤–µ–∑–¥–æ—á–∫–æ–π ‚≠ê –î–æ–±–∞–≤–ª—è–π—Ç–µ —Ü–µ–Ω–Ω—ã–µ –±—É–º–∞–≥–∏ –≤ ¬´–ò–∑–±—Ä–∞–Ω–Ω–æ–µ¬ª, —á—Ç–æ–±—ã –ø–æ—Ç–æ–º –ª–µ–≥–∫–æ –Ω–∞–π—Ç–∏ –∏—Ö. –ò–¥–µ–º –∏—Å–∫–∞—Ç—å —Ü–µ–Ω–Ω—ã–µ –±—É–º–∞–≥–∏ ‚Äî> —Ä–∞–∑–¥–µ–ª ¬´–ß—Ç–æ –∫—É–ø–∏—Ç—å¬ª üîç –ï—Å–ª–∏ —Ö–æ—Ç–∏—Ç–µ —á—Ç–æ-—Ç–æ –∫—É–ø–∏—Ç—å, —ç—Ç–æ—Ç —Ä–∞–∑–¥–µ–ª —Å–∞–º—ã–π –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã–π (–∏ –Ω—É–∂–Ω—ã–π). –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –Ω–∞–π—Ç–∏ –∞–∫—Ç–∏–≤, –ø—Ä–æ–≥–Ω–æ–∑—ã –∞–Ω–∞–ª–∏—Ç–∏–∫–æ–≤ –∏ —É–∂–µ –≥–æ—Ç–æ–≤—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é. üëâ –í–µ—Ä—Ö–Ω—è—è –ø–∞–Ω–µ–ª—å ‚Äî –≤—Å–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –∏–Ω–≤–µ—Å—Ç–æ—Ä–∞. –ï—Å–ª–∏ –≤—ã –Ω–æ–≤–∏—á–æ–∫, –∑–∞–≥–ª—è–Ω–∏—Ç–µ –≤–æ –≤–∫–ª–∞–¥–∫–∏ ¬´–ê–∫—Ü–∏–∏¬ª –∏ ¬´–û–±–ª–∏–≥–∞—Ü–∏–∏¬ª. –ò–¥–µ–º –∏—Å–∫–∞—Ç—å —Ü–µ–Ω–Ω—ã–µ –±—É–º–∞–≥–∏ ‚Äî> —Ä–∞–∑–¥–µ–ª ¬´–ß—Ç–æ –∫—É–ø–∏—Ç—å¬ª üîç –ï—Å–ª–∏ —Ö–æ—Ç–∏—Ç–µ —á—Ç–æ-—Ç–æ –∫—É–ø–∏—Ç—å, —ç—Ç–æ—Ç —Ä–∞–∑–¥–µ–ª —Å–∞–º—ã–π –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã–π (–∏ –Ω—É–∂–Ω—ã–π). –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –Ω–∞–π—Ç–∏ –∞–∫—Ç–∏–≤, –ø—Ä–æ–≥–Ω–æ–∑—ã –∞–Ω–∞–ª–∏—Ç–∏–∫–æ–≤ –∏ —É–∂–µ –≥–æ—Ç–æ–≤—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é. üëâ –í–µ—Ä—Ö–Ω—è—è –ø–∞–Ω–µ–ª—å ‚Äî –≤—Å–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –∏–Ω–≤–µ—Å—Ç–æ—Ä–∞. –ï—Å–ª–∏ –≤—ã –Ω–æ–≤–∏—á–æ–∫, –∑–∞–≥–ª—è–Ω–∏—Ç–µ –≤–æ –≤–∫–ª–∞–¥–∫–∏ ¬´–ê–∫—Ü–∏–∏¬ª –∏ ¬´–û–±–ª–∏–≥–∞—Ü–∏–∏¬ª. –ï—Å–ª–∏ —è –Ω–µ –∑–Ω–∞—é, —á—Ç–æ –∫—É–ø–∏—Ç—å ‚Äî> –ø–æ–¥–±–æ—Ä–∫–∏ –æ—Ç –∞–Ω–∞–ª–∏—Ç–∏–∫–æ–≤ üëâ –í'),\n",
       " Document(page_content='–≤—ã –º–æ–∂–µ—Ç–µ –æ–±—Ä–∞—Ç–∏—Ç—å—Å—è –≤ –ø–æ–¥–¥–µ—Ä–∂–∫—É –¢-–ò–Ω–≤–µ—Å—Ç–∏—Ü–∏–π. –ê –µ—Å–ª–∏ –≤—ã —Ö–æ—Ç–∏—Ç–µ –Ω–∞—É—á–∏—Ç—å—Å—è —Ç–∞–∫ –∂–µ –±—ã—Å—Ç—Ä–æ –Ω–∞—Ö–æ–¥–∏—Ç—å –Ω–µ —Ç–æ–ª—å–∫–æ –±—é–¥–∂–µ—Ç–Ω—ã–µ, –Ω–æ –∏ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –∫–æ–º–ø–∞–Ω–∏–∏, —á–∏—Ç–∞–π—Ç–µ –Ω–∞—à –∫—É—Ä—Å ¬´–ß–µ–∫-–ª–∏—Å—Ç: –∫–∞–∫ –±—ã—Å—Ç—Ä–æ –≤—ã–±—Ä–∞—Ç—å –ª—É—á—à—É—é –∞–∫—Ü–∏—é¬ª. –ö–∞–∫ –±—ã—Ç—å –≤ –∫—É—Ä—Å–µ –≤—Å–µ—Ö –∫–æ–Ω–∫—É—Ä—Å–æ–≤ üëâ –ß—Ç–æ–±—ã —É–∑–Ω–∞–≤–∞—Ç—å –æ–±–æ –≤—Å–µ—Ö –∞–∫—Ü–∏—è—Ö –∏ –∫–æ–Ω–∫—É—Ä—Å–∞—Ö, –ø–æ–¥–ø–∏—à–∏—Ç–µ—Å—å –≤ –ü—É–ª—å—Å–µ –Ω–∞ –∞–∫–∫–∞—É–Ω—Ç—ã Pulse_Official –∏ T-Investments. –¢–∞–∫–∂–µ –≤—ã –º–æ–∂–µ—Ç–µ –æ–±—Ä–∞—Ç–∏—Ç—å—Å—è –≤ –ø–æ–¥–¥–µ—Ä–∂–∫—É –¢-–ò–Ω–≤–µ—Å—Ç–∏—Ü–∏–π. –ê –µ—Å–ª–∏ –≤—ã —Ö–æ—Ç–∏—Ç–µ –Ω–∞—É—á–∏—Ç—å—Å—è —Ç–∞–∫ –∂–µ –±—ã—Å—Ç—Ä–æ –Ω–∞—Ö–æ–¥–∏—Ç—å –Ω–µ —Ç–æ–ª—å–∫–æ –±—é–¥–∂–µ—Ç–Ω—ã–µ, –Ω–æ –∏ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –∫–æ–º–ø–∞–Ω–∏–∏, —á–∏—Ç–∞–π—Ç–µ –Ω–∞—à –∫—É—Ä—Å ¬´–ß–µ–∫-–ª–∏—Å—Ç: –∫–∞–∫ –±—ã—Å—Ç—Ä–æ –≤—ã–±—Ä–∞—Ç—å –ª—É—á—à—É—é –∞–∫—Ü–∏—é¬ª.  –ó–∞—á–µ–º –Ω—É–∂–Ω—ã –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏ –£—Ä–æ–∫ 1 10 –º–∏–Ω –ü—Ä–æ–≥—Ä–µ—Å—Å 6% ‚òùÔ∏è –ß—Ç–æ –≤—ã —É–∑–Ω–∞–µ—Ç–µ –° –∫–∞–∫–æ–π —Å–∫–æ—Ä–æ—Å—Ç—å—é —Ä–∞—Å—Ç—É—Ç —Ü–µ–Ω—ã –≤ –†–æ—Å—Å–∏–∏ –∏ —á—Ç–æ —Å —ç—Ç–∏–º –¥–µ–ª–∞—Ç—å –ü–æ—á–µ–º—É –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏ –≤—ã–≥–æ–¥–Ω–µ–µ –≤–∫–ª–∞–¥–æ–≤ –∏ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏ –ö–∞–∫ –¥–æ—Å—Ç–∏—á—å —Ü–µ–ª–µ–π —Å –ø–æ–º–æ—â—å—é –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–π ‚òùÔ∏è –ß–µ–º—É –≤—ã –Ω–∞—É—á–∏—Ç–µ—Å—å –ü—Ä–∞–≤–∏–ª—å–Ω–æ –≤—ã–±–∏—Ä–∞—Ç—å –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –¥–ª—è –∑–∞—Ä–∞–±–æ—Ç–∫–∞ –û–±–≥–æ–Ω—è—Ç—å —Ä–æ—Å—Ç —Ü–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É—è —Ä–∞–∑–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã ‚òùÔ∏è –ß—Ç–æ –≤—ã —É–∑–Ω–∞–µ—Ç–µ ‚òùÔ∏è –ß–µ–º—É –≤—ã –Ω–∞—É—á–∏—Ç–µ—Å—å –°–ª–æ–≤–∞—Ä—å'),\n",
       " Document(page_content='–∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π. –ü—Ä–æ—Ñ–∏–ª—å–Ω—ã–µ DIY-–∏–≥—Ä–æ–∫–∏, –æ—Å–æ–±–µ–Ω–Ω–æ –í–ò.—Ä—É, –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è—é—Ç –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–π –∏ –ø–æ–¥–¥–µ—Ä–∂–∫—É –ø—Ä–∏ –ø–æ–∫—É–ø–∫–µ. –≠—Ç–æ —É–∂–µ –∏—Ö –≤–∞–∂–Ω–æ–µ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω–æ–µ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–æ –ø–µ—Ä–µ–¥ –º–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å–∞–º–∏. –ü–æ–º–∏–º–æ –ø–æ–¥–¥–µ—Ä–∂–∫–∏ —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–æ–≤, –≤–∞–∂–Ω—ã–º –∫—Ä–∏—Ç–µ—Ä–∏–µ–º –≤—ã–±–æ—Ä–∞ –¥–ª—è B2B-—Å–µ–≥–º–µ–Ω—Ç–∞ —è–≤–ª—è–µ—Ç—Å—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –∑–∞–∫—Ä—ã—Ç—å –≤—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç–∏ –≤ —Ä–∞–º–∫–∞—Ö –µ–¥–∏–Ω–æ–≥–æ –∑–∞–∫–∞–∑–∞ ‚Äî —Ç–∞–∫—É—é –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –º–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å—ã –º–æ–≥—É—Ç –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏—Ç—å –≤ –æ—Ç–ª–∏—á–∏–µ –æ—Ç –ø—Ä–æ—Ñ–∏–ª—å–Ω—ã—Ö –∏–≥—Ä–æ–∫–æ–≤. –í–ò.—Ä—É —Ç–∞–∫–∂–µ –æ—Ç–≤–µ—á–∞–µ—Ç –∑–∞ –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç—å –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–∫–∞–∑–∞ –≤ —Å—Ä–æ–∫, —á—Ç–æ —è–≤–ª—è–µ—Ç—Å—è –≤–∞–∂–Ω—ã–º –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω—ã–º –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–æ–º, —Ç–∞–∫ –∫–∞–∫ –º–Ω–æ–≥–∏–µ –ø—Ä–æ—Ü–µ—Å—Å—ã –≤ —Ä–µ–º–æ–Ω—Ç–µ/—Å—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤–µ –Ω–µ —Ç–µ—Ä–ø—è—Ç –∑–∞–¥–µ—Ä–∂–µ–∫. –ê —É–≤–µ–ª–∏—á–µ–Ω–∏–µ –¥–æ–ª–∏ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã—Ö –±—Ä–µ–Ω–¥–æ–≤ –∏ —ç–∫—Å–∫–ª—é–∑–∏–≤–Ω—ã—Ö –ø–∞—Ä—Ç–Ω–µ—Ä—Å—Ç–≤ –≤ –æ–±—â–µ–º –∞—Å—Å–æ—Ä—Ç–∏–º–µ–Ω—Ç–µ –∫–æ–º–ø–∞–Ω–∏–∏ –¥–µ–ª–∞–µ—Ç –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –í–ò.—Ä—É —É–Ω–∏–∫–∞–ª—å–Ω—ã–º. –ö–∞–∫ –º—ã —É–∂–µ –ø–∏—Å–∞–ª–∏ –≤—ã—à–µ, –í–ò.—Ä—É –∑–∞–Ω–∏–º–∞–µ—Ç –≤—Ç–æ—Ä–æ–µ –º–µ—Å—Ç–æ –ø–æ —Ä–∞–∑–º–µ—Ä—É –æ–±—â–µ–π –≤—ã—Ä—É—á–∫–∏ —Å—Ä–µ–¥–∏ –ø—Ä–æ—Ñ–∏–ª—å–Ω—ã—Ö –∏–≥—Ä–æ–∫–æ–≤ –∏ –ø–µ—Ä–≤–æ–µ –º–µ—Å—Ç–æ –ø–æ –¥–æ—Ö–æ–¥–∞–º –æ—Ç –æ–Ω–ª–∞–π–Ω-–ø—Ä–æ–¥–∞–∂. –ö–æ–º–ø–∞–Ω–∏—è –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –º–æ—â–Ω—ã–µ —Ç–µ–º–ø—ã —Ä–æ—Å—Ç–∞ –≤—ã—Ä—É—á–∫–∏,'),\n",
       " Document(page_content='–¥—Ä—É–≥–∏–µ –∞–∫—Ç–∏–≤—ã. üìù –ê–∫—Ü–∏–∏ –ò—Ç–∞–∫, –º—ã –Ω–∞—á–Ω–µ–º —Å —Ç–æ–≥–æ, –æ —á–µ–º –≤—ã —Ç–æ—á–Ω–æ —Å–ª—ã—à–∞–ª–∏. üìå –ê–∫—Ü–∏—è ‚Äî —ç—Ç–æ –¥–æ–ª—è –≤ –∫–æ–º–ø–∞–Ω–∏–∏, –∫–æ—Ç–æ—Ä—É—é –∏–Ω–≤–µ—Å—Ç–æ—Ä—ã –º–æ–≥—É—Ç –ø—Ä–æ–¥–∞–≤–∞—Ç—å –∏ –ø–æ–∫—É–ø–∞—Ç—å. –ö—É–ø–∏–≤ –∞–∫—Ü–∏–∏, –≤—ã —Å—Ç–∞–Ω–æ–≤–∏—Ç–µ—Å—å —Å–æ–≤–ª–∞–¥–µ–ª—å—Ü–µ–º –±–∏–∑–Ω–µ—Å–∞ –∏ –º–æ–∂–µ—Ç–µ —Ä–∞–∑–¥–µ–ª–∏—Ç—å –µ–≥–æ —É—Å–ø–µ—Ö–∏, –Ω–∞–ø—Ä–∏–º–µ—Ä –ø–æ–ª—É—á–∏—Ç—å –¥–∏–≤–∏–¥–µ–Ω–¥—ã ‚Äî —á–∞—Å—Ç—å –ø—Ä–∏–±—ã–ª–∏, –∫–æ—Ç–æ—Ä–æ–π –∫–æ–º–ø–∞–Ω–∏—è –¥–µ–ª–∏—Ç—Å—è —Å –∏–Ω–≤–µ—Å—Ç–æ—Ä–∞–º–∏, –≤–ª–∞–¥–µ—é—â–∏–º–∏ –∏—Ö –∞–∫—Ü–∏—è–º–∏. –ë–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ –∏–Ω–≤–µ—Å—Ç–æ—Ä–æ–≤ –ø–æ–∫—É–ø–∞–µ—Ç –∏–º–µ–Ω–Ω–æ –∞–∫—Ü–∏–∏. –¢–∞–∫ –∫–∞–∫ –∞–∫—Ü–∏–∏ –º–æ–≥—É—Ç –±—ã—Ç—å –æ—á–µ–Ω—å –¥–µ—à–µ–≤—ã–º–∏ –∏ –º–æ–≥—É—Ç –±—ã—Å—Ç—Ä–æ –ø—Ä–∏–Ω–µ—Å—Ç–∏ –ø—Ä–∏–±—ã–ª—å. –ò –∫—Å—Ç–∞—Ç–∏, –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å –∞–∫—Ü–∏–π –Ω–∞ –±–æ–ª—å—à–æ–º –ø—Ä–æ–º–µ–∂—É—Ç–∫–µ –≤—Ä–µ–º–µ–Ω–∏ –æ–ø–µ—Ä–µ–∂–∞–µ—Ç –¥—Ä—É–≥–∏–µ –∞–∫—Ç–∏–≤—ã. –ò—Å—Ç–æ—Ä–∏—è –æ —Ç–æ–º, –∫–∞–∫ –∏–Ω–≤–µ—Å—Ç–æ—Ä—ã –Ω–∞—Ö–æ–¥—è—Ç –ª—é–±–∏–º—ã–µ –∞–∫—Ü–∏–∏ –ó–∞ —Å—á–µ—Ç —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è –±—É–º–∞–≥ –Ω–∞ –±–∏—Ä–∂–µ –≤—ã –≤—Å–µ–≥–¥–∞ –º–æ–∂–µ—Ç–µ –Ω–∞–π—Ç–∏ —Ç—É –∞–∫—Ü–∏—é, –∫–æ—Ç–æ—Ä–∞—è –ø–æ–¥–æ–π–¥–µ—Ç –≤–∞–º –∫–∞–∫ –ø–æ –±—é–¥–∂–µ—Ç—É, —Ç–∞–∫ –∏ –ø–æ —Ü–µ–ª–∏. –¢–∞–∫ —Å–ª—É—á–∏–ª–æ—Å—å –∏ —Å –Ω–∞—à–∏–º –∏–Ω–≤–µ—Å—Ç–æ—Ä–æ–º. –ò—Å—Ç–æ—Ä–∏—è –æ —Ç–æ–º, –∫–∞–∫ –∏–Ω–≤–µ—Å—Ç–æ—Ä—ã –Ω–∞—Ö–æ–¥—è—Ç –ª—é–±–∏–º—ã–µ –∞–∫—Ü–∏–∏ –ó–∞ —Å—á–µ—Ç —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è –±—É–º–∞–≥ –Ω–∞ –±–∏—Ä–∂–µ –≤—ã –≤—Å–µ–≥–¥–∞ –º–æ–∂–µ—Ç–µ –Ω–∞–π—Ç–∏ —Ç—É –∞–∫—Ü–∏—é, –∫–æ—Ç–æ—Ä–∞—è –ø–æ–¥–æ–π–¥–µ—Ç –≤–∞–º –∫–∞–∫ –ø–æ –±—é–¥–∂–µ—Ç—É, —Ç–∞–∫ –∏ –ø–æ —Ü–µ–ª–∏. –¢–∞–∫')]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ù–∞ –æ—Å–Ω–æ–≤–∞–Ω–∏–∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞, –º–æ–∂–Ω–æ –≤—ã–¥–µ–ª–∏—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ñ–∞–∫—Ç–æ—Ä–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –¥–µ–ª–∞—é—Ç –∞–∫—Ü–∏–∏ IT-–∫–æ–º–ø–∞–Ω–∏–π –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã–º–∏ –¥–ª—è –ø—Ä–∏–æ–±—Ä–µ—Ç–µ–Ω–∏—è:\n",
      "\n",
      "1. **–†–∞–∑–≤–∏—Ç–∏–µ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã—Ö –ø—Ä–æ–¥—É–∫—Ç–æ–≤**: –£–ø–æ–º–∏–Ω–∞–µ—Ç—Å—è, —á—Ç–æ –∫–æ–º–ø–∞–Ω–∏–∏, —Ä–∞–∑–≤–∏–≤–∞—é—â–∏–µ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è, –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç –≤—ã—Å–æ–∫—É—é —Ä–µ–Ω—Ç–∞–±–µ–ª—å–Ω–æ—Å—Ç—å. –ù–∞–ø—Ä–∏–º–µ—Ä, –≤–∞–ª–æ–≤–∞—è –ø—Ä–∏–±—ã–ª—å –æ—Ç —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã—Ö –ø—Ä–æ–¥—É–∫—Ç–æ–≤ —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç –æ–∫–æ–ª–æ 60%, —á—Ç–æ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ –≤—ã—à–µ, —á–µ–º —É —Å—Ç–æ—Ä–æ–Ω–Ω–∏—Ö –ø—Ä–æ–¥—É–∫—Ç–æ–≤ (–æ–∫–æ–ª–æ 13%). –≠—Ç–æ –¥–µ–ª–∞–µ—Ç —Ç–∞–∫–∏–µ –∫–æ–º–ø–∞–Ω–∏–∏ –±–æ–ª–µ–µ –ø—Ä–∏–≤–ª–µ–∫–∞—Ç–µ–ª—å–Ω—ã–º–∏ –¥–ª—è –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–π.\n",
      "\n",
      "2. **–°—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –Ω–∞ —Ä—ã–Ω–∫–µ**: –ö–æ–º–ø–∞–Ω–∏–∏, –∫–æ—Ç–æ—Ä—ã–µ –≤—ã–∏–≥—Ä—ã–≤–∞—é—Ç –æ—Ç –ø–µ—Ä–µ—Å—Ç—Ä–æ–π–∫–∏ IT-—Ä—ã–Ω–∫–∞ –∏ –∞–∫—Ç–∏–≤–Ω–æ–≥–æ –∏–º–ø–æ—Ä—Ç–æ–∑–∞–º–µ—â–µ–Ω–∏—è, —Ç–∞–∫–∂–µ –º–æ–≥—É—Ç –±—ã—Ç—å –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã–º–∏ –¥–ª—è –∏–Ω–≤–µ—Å—Ç–æ—Ä–æ–≤. –≠—Ç–æ —Å–≤—è–∑–∞–Ω–æ —Å —Ä–æ—Å—Ç–æ–º –ø—Ä–∏–±—ã–ª—å–Ω–æ—Å—Ç–∏ –∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é –∑–∞—Ö–≤–∞—Ç–∞ –Ω–æ–≤—ã—Ö —Ä—ã–Ω–æ—á–Ω—ã—Ö –Ω–∏—à.\n",
      "\n",
      "3. **–°–ª–∏—è–Ω–∏—è –∏ –ø–æ–≥–ª–æ—â–µ–Ω–∏—è (M&A)**: –ö–æ–º–ø–∞–Ω–∏–∏, –∞–∫—Ç–∏–≤–Ω–æ –∑–∞–Ω–∏–º–∞—é—â–∏–µ—Å—è —Å–¥–µ–ª–∫–∞–º–∏ —Å–ª–∏—è–Ω–∏–π –∏ –ø–æ–≥–ª–æ—â–µ–Ω–∏–π, –º–æ–≥—É—Ç –ø—Ä–æ–¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä–æ–≤–∞—Ç—å –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–π —Ä–æ—Å—Ç. –ù–∞–ø—Ä–∏–º–µ—Ä, –æ–¥–Ω–∞ –∏–∑ –∫–æ–º–ø–∞–Ω–∏–π –∑–∞–≤–µ—Ä—à–∏–ª–∞ –±–æ–ª–µ–µ –≤–æ—Å—å–º–∏ —Å–¥–µ–ª–æ–∫ –≤ —Ä–∞–∑–Ω—ã—Ö —Å–µ–≥–º–µ–Ω—Ç–∞—Ö —Ä—ã–Ω–∫–∞, —á—Ç–æ –º–æ–∂–µ—Ç —Å–≤–∏–¥–µ—Ç–µ–ª—å—Å—Ç–≤–æ–≤–∞—Ç—å –æ –µ—ë —Å—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–æ–º —Ä–∞–∑–≤–∏—Ç–∏–∏ –∏ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–∏.\n",
      "\n",
      "4. **–î–∏–≤–∏–¥–µ–Ω–¥–Ω–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å**: –û–∂–∏–¥–∞–µ–º–∞—è –¥–∏–≤–∏–¥–µ–Ω–¥–Ω–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å –Ω–∞ —É—Ä–æ–≤–Ω–µ 8% –∏ 13% –ø–æ –∏—Ç–æ–≥–∞–º 2025 –∏ 2026 –≥–æ–¥–æ–≤ —Ç–∞–∫–∂–µ –¥–µ–ª–∞–µ—Ç –∞–∫—Ü–∏–∏ –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö IT-–∫–æ–º–ø–∞–Ω–∏–π –ø—Ä–∏–≤–ª–µ–∫–∞—Ç–µ–ª—å–Ω—ã–º–∏ –¥–ª—è –∏–Ω–≤–µ—Å—Ç–æ—Ä–æ–≤, –∏—â—É—â–∏—Ö —Å—Ç–∞–±–∏–ª—å–Ω—ã–π –¥–æ—Ö–æ–¥.\n",
      "\n",
      "–¢–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º, –¥–ª—è –≤—ã–±–æ—Ä–∞ –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã—Ö –∞–∫—Ü–∏–π IT-–∫–æ–º–ø–∞–Ω–∏–π —Å—Ç–æ–∏—Ç –æ–±—Ä–∞—Ç–∏—Ç—å –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ —Ç–µ, –∫–æ—Ç–æ—Ä—ã–µ –∞–∫—Ç–∏–≤–Ω–æ —Ä–∞–∑–≤–∏–≤–∞—é—Ç —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–æ–¥—É–∫—Ç—ã, —É—á–∞—Å—Ç–≤—É—é—Ç –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã—Ö –∏–∑–º–µ–Ω–µ–Ω–∏—è—Ö –Ω–∞ —Ä—ã–Ω–∫–µ, –∑–∞–Ω–∏–º–∞—é—Ç—Å—è —Å–ª–∏—è–Ω–∏—è–º–∏ –∏ –ø–æ–≥–ª–æ—â–µ–Ω–∏—è–º–∏, –∞ —Ç–∞–∫–∂–µ –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç –ø—Ä–∏–≤–ª–µ–∫–∞—Ç–µ–ª—å–Ω—É—é –¥–∏–≤–∏–¥–µ–Ω–¥–Ω—É—é –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å.\n"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "# RAG\n",
    "template = \"\"\"Answer the following question based on this context:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "final_rag_chain = (\n",
    "    {\"context\": retrieval_chain, \n",
    "     \"question\": itemgetter(\"question\")} \n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "res = final_rag_chain.invoke({\"question\":question})\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.load.serializable import to_json_not_implemented\n",
    "\n",
    "repr = to_json_not_implemented(final_rag_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lc': 1,\n",
       " 'type': 'not_implemented',\n",
       " 'id': ['langchain_core', 'runnables', 'base', 'RunnableSequence'],\n",
       " 'repr': \"{\\n  context: ChatPromptTemplate(input_variables=['question'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], template='You are an AI language model assistant. Your task is to generate five \\\\ndifferent versions of the given user question to retrieve relevant documents from a vector \\\\ndatabase. By generating multiple perspectives on the user question, your goal is to help\\\\nthe user overcome some of the limitations of the distance-based similarity search. \\\\nProvide these alternative questions separated by newlines. Original question: {question}'))])\\n           | ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x308f7a490>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x3424bcb90>, root_client=<openai.OpenAI object at 0x177459690>, root_async_client=<openai.AsyncOpenAI object at 0x308f7a950>, model_name='gpt-4o-mini', temperature=0.0, openai_api_key=SecretStr('**********'), openai_api_base='https://api.proxyapi.ru/openai/v1', openai_proxy='', max_tokens=1000)\\n           | StrOutputParser()\\n           | RunnableLambda(...)\\n           | RunnableEach(bound=VectorStoreRetriever(tags=['Chroma', 'HuggingFaceEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x111af9090>))\\n           | RunnableLambda(get_unique_union),\\n  question: RunnableLambda(itemgetter('question'))\\n}\\n| ChatPromptTemplate(input_variables=['context', 'question'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], template='Answer the following question based on this context:\\\\n\\\\n{context}\\\\n\\\\nQuestion: {question}\\\\n'))])\\n| ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x308f7a490>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x3424bcb90>, root_client=<openai.OpenAI object at 0x177459690>, root_async_client=<openai.AsyncOpenAI object at 0x308f7a950>, model_name='gpt-4o-mini', temperature=0.0, openai_api_key=SecretStr('**********'), openai_api_base='https://api.proxyapi.ru/openai/v1', openai_proxy='', max_tokens=1000)\\n| StrOutputParser()\"}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"lc\": 1,\n",
      "  \"type\": \"not_implemented\",\n",
      "  \"id\": [\n",
      "    \"langchain_core\",\n",
      "    \"vectorstores\",\n",
      "    \"base\",\n",
      "    \"VectorStoreRetriever\"\n",
      "  ],\n",
      "  \"repr\": \"VectorStoreRetriever(tags=['Chroma', 'HuggingFaceEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x111af9090>)\",\n",
      "  \"name\": \"VectorStoreRetriever\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "string_representation = dumps(final_rag_chain, pretty=True)\n",
    "print(string_representation[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"../../artifacts/chain.json\", \"w\") as fp:\n",
    "    json.dump(repr, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../artifacts/chain.json\", \"r\") as fp:\n",
    "    chain_dict = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lc': 1,\n",
       " 'type': 'not_implemented',\n",
       " 'id': ['langchain_core', 'runnables', 'base', 'RunnableSequence'],\n",
       " 'repr': \"{\\n  context: ChatPromptTemplate(input_variables=['question'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], template='You are an AI language model assistant. Your task is to generate five \\\\ndifferent versions of the given user question to retrieve relevant documents from a vector \\\\ndatabase. By generating multiple perspectives on the user question, your goal is to help\\\\nthe user overcome some of the limitations of the distance-based similarity search. \\\\nProvide these alternative questions separated by newlines. Original question: {question}'))])\\n           | ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x308f7a490>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x3424bcb90>, root_client=<openai.OpenAI object at 0x177459690>, root_async_client=<openai.AsyncOpenAI object at 0x308f7a950>, model_name='gpt-4o-mini', temperature=0.0, openai_api_key=SecretStr('**********'), openai_api_base='https://api.proxyapi.ru/openai/v1', openai_proxy='', max_tokens=1000)\\n           | StrOutputParser()\\n           | RunnableLambda(...)\\n           | RunnableEach(bound=VectorStoreRetriever(tags=['Chroma', 'HuggingFaceEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x111af9090>))\\n           | RunnableLambda(get_unique_union),\\n  question: RunnableLambda(itemgetter('question'))\\n}\\n| ChatPromptTemplate(input_variables=['context', 'question'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], template='Answer the following question based on this context:\\\\n\\\\n{context}\\\\n\\\\nQuestion: {question}\\\\n'))])\\n| ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x308f7a490>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x3424bcb90>, root_client=<openai.OpenAI object at 0x177459690>, root_async_client=<openai.AsyncOpenAI object at 0x308f7a950>, model_name='gpt-4o-mini', temperature=0.0, openai_api_key=SecretStr('**********'), openai_api_base='https://api.proxyapi.ru/openai/v1', openai_proxy='', max_tokens=1000)\\n| StrOutputParser()\"}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
